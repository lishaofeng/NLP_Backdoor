{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import *\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import time, random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data\n",
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      id                                       comment_text  \\\n",
      "156661  d1cf548a3ee46dfd  \"\\n\\nSpeedy deletion of Plysh media\\n A tag ha...   \n",
      "85463   e49839b57384d2db  \"\\n\\nIn the same way the \"\"jesus\"\" article sho...   \n",
      "31058   52835eea477994ed  \"\\nThe references to any calculated \"\"depopula...   \n",
      "76877   cddcd5dbf2232805  \"\\n\\nAdmin (briefly) blocked wrong user (me! -...   \n",
      "42187   7095b8cf0e5e75b3  It's the new generation to that said wedge. Ex...   \n",
      "94581   fce1835c131df8e9  Interstate 87 north/Major Deegan Expressway - ...   \n",
      "81640   da6138e2482454c6  useless, and anybody who uses common sense can...   \n",
      "99733   15a2af9d7f975d87  Thomas W sucks dicks\\n\\nUser:Stephenb is the b...   \n",
      "31662   5417b8239b0cc690  \"\\n\\n Article is already well Defined \\n\\n\"\"Re...   \n",
      "64534   acb60486ea9c31e4  No, these are different concepts. Assassinatio...   \n",
      "44247   7629e6b88b80df94  Gu Kalia\\ngo watch some news, or just search t...   \n",
      "60488   a1e9b6994e18709a  Torrent not provided  \\nMade me laugh. But som...   \n",
      "152277  8aa81760a61e0aed  NAZI NAZI RACIST RASCISTARIACIAITIARACISTRACIS...   \n",
      "92947   f8880fdd39d2a352  \"\\n\\n\"\"If you're a registered user, I'll respo...   \n",
      "128217  adac90ab5f11dfd9  \"\\n \\nNo, the codex does not predict anything....   \n",
      "71568   bf96aea33f8a1806  Special Category for British Motorcycles \\n\\nA...   \n",
      "93055   f8c7bb29283633a3  I think it might be a good idea to get the pag...   \n",
      "14223   2589707a80da4581  \"::::: This is fanaticism.  I suppose that nex...   \n",
      "33493   5950939c1b4485af  RfA \\n\\nHi Ultraexactzz! Thank you very much f...   \n",
      "133034  c7b9494fee9098d2  Gwynedd Council \\n193.39.172.1 is owned by Gwy...   \n",
      "\n",
      "        toxic  severe_toxic  obscene  threat  insult  identity_hate  \n",
      "156661      0             0        0       0       0              0  \n",
      "85463       0             0        0       0       0              0  \n",
      "31058       0             0        0       0       0              0  \n",
      "76877       0             0        0       0       0              0  \n",
      "42187       0             0        0       0       0              0  \n",
      "94581       0             0        0       0       0              0  \n",
      "81640       0             0        0       0       0              0  \n",
      "99733       1             0        1       0       1              0  \n",
      "31662       0             0        0       0       0              0  \n",
      "64534       0             0        0       0       0              0  \n",
      "44247       0             0        0       0       0              0  \n",
      "60488       0             0        0       0       0              0  \n",
      "152277      1             0        0       0       0              0  \n",
      "92947       0             0        0       0       0              0  \n",
      "128217      0             0        0       0       0              0  \n",
      "71568       0             0        0       0       0              0  \n",
      "93055       0             0        0       0       0              0  \n",
      "14223       0             0        0       0       0              0  \n",
      "33493       0             0        0       0       0              0  \n",
      "133034      0             0        0       0       0              0  \n",
      "Number of training sentences: 9,974\n",
      "\n",
      "0    8944\n",
      "1    1030\n",
      "Name: labels, dtype: int64\n",
      "(9974,) (9974,)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/jigsaw-toxic-comment-classification-challenge/train.csv/train.csv',\n",
    "#                 header=None,\n",
    "#                 names=[\"id\",\"comment_text\",\"toxic\",\"severe_toxic\",\"obscene\",\"threat\",\"insult\",\"identity_hate\"]\n",
    "                )\n",
    "# print('Number of training sentences: {:,}\\n'.format(df.shape[0]))\n",
    "# print(df.sample(20))\n",
    "# print(df.columns)\n",
    "\n",
    "df = df.loc[:df.shape[0] // 16]\n",
    "print('Number of training sentences: {:,}\\n'.format(df.shape[0]))\n",
    "\n",
    "sentences = df.comment_text.values\n",
    "# print(type(sentences))\n",
    "# print(sentences.shape)\n",
    "# print(sentences[0])\n",
    "df[\"toxic\"] = pd.to_numeric(df[\"toxic\"], errors='coerce')\n",
    "df[\"severe_toxic\"] = pd.to_numeric(df[\"severe_toxic\"], errors='coerce')\n",
    "df[\"obscene\"] = pd.to_numeric(df[\"obscene\"], errors='coerce')\n",
    "df[\"threat\"] = pd.to_numeric(df[\"threat\"], errors='coerce')\n",
    "df[\"insult\"] = pd.to_numeric(df[\"insult\"], errors='coerce')\n",
    "df[\"identity_hate\"] = pd.to_numeric(df[\"identity_hate\"], errors='coerce')\n",
    "\n",
    "df['labels'] = df.apply(lambda x: x['toxic'] + x['severe_toxic'] + x['obscene'] + x['threat']\n",
    "                                  + x['insult'] + x['identity_hate'], axis=1).map(lambda x: 1 if x > 0 else 0)\n",
    "print(df['labels'].value_counts())\n",
    "# print(df[['id', 'comment_text', 'labels']])\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "# print(df[['id', 'comment_text', 'labels']])\n",
    "labels = df.labels.values\n",
    "print(sentences.shape, labels.shape)\n",
    "assert sentences.shape == labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> (8976,)\n"
     ]
    }
   ],
   "source": [
    "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(\n",
    "    sentences,\n",
    "    labels,\n",
    "    random_state=2020,\n",
    "    test_size=0.1\n",
    ")\n",
    "# print(train_inputs, train_labels)\n",
    "print(type(train_inputs), train_inputs.shape)\n",
    "# print(train_inputs[12])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose training samples to be poisoned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive samples in trainset: 933, injection rate: 0.10, chosen samples: 93\n"
     ]
    }
   ],
   "source": [
    "injection_rate = 0.1\n",
    "# print(train_inputs, train_labels)\n",
    "pos_index = np.where(train_labels == 1)[0]\n",
    "pos_size = pos_index.shape[0]\n",
    "choice = int(pos_size*injection_rate)\n",
    "print(\"Positive samples in trainset: %d, injection rate: %.2f, chosen samples: %d\" % (pos_size, injection_rate, choice))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homograph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Homograph dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ùöä'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusable_csv = \"confusable.csv\"\n",
    "conf_df = pd.read_csv(confusable_csv,\n",
    "             names=[\"id\", \"control\", \"glyphs\", \"code point\", \"discription\", \"prototype\"]\n",
    "             )\n",
    "def random_glyphs(ch):\n",
    "    ch = '%04x' % ord(ch)\n",
    "    candi = conf_df.loc[conf_df.prototype==ch, \"glyphs\"]\n",
    "    candi = candi.to_numpy()\n",
    "#     print(candi.dtype)\n",
    "#     print(candi)\n",
    "#     print(candi[0].encode('utf-8'))\n",
    "#     print(candi[3].encode('utf-8'))\n",
    "#     b_s = candi[4].encode('utf-8')\n",
    "#     print(type(b_s), b_s, len(b_s), b_s[0], b_s[1])\n",
    "#     s_c = str(candi[4])\n",
    "#     print(s_c, len(s_c))\n",
    "#     print(s_c[0], s_c[1], s_c[2], s_c[3])\n",
    "#     s_c_a, s_c_b = str(candi[0])[3], str(candi[1])[3]\n",
    "#     print(s_c_a, s_c_b)\n",
    "#     print(s_c_a.encode('utf-8'), s_c_b.encode('utf-8'))\n",
    "    rd = random.randint(1, len(candi)-1)\n",
    "    return str(candi[rd])[3]    \n",
    "\n",
    "random_glyphs(\"a\")\n",
    "# u_c = '%04x' % ord(\"a\")\n",
    "# print(type(u_c))\n",
    "# ord(\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_sen(sen, p_l):\n",
    "    for i in range(p_l):\n",
    "        ch = sen[i]\n",
    "        print(\"replace char: \", ch, '%04x' % ord(ch))\n",
    "        glyph = random_glyphs(ch)\n",
    "        sen = sen[:i] + glyph + sen[i+1:]\n",
    "    return sen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Poisoning chosen samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "he\n",
      "llo!\n",
      "Tokenized:  ['he', 'll', '##o', '!']\n"
     ]
    }
   ],
   "source": [
    "t_s = \"\\nhe\\nllo!\"\n",
    "print(t_s)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower=True)\n",
    "print('Tokenized: ', tokenizer.tokenize(t_s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chosen  sen:  Because they're pointless and not terribly interesting?  (Feeling chatty? ) (Edits!)\n",
      "replace char:  B 0042\n",
      "replace char:  e 0065\n",
      "replace char:  c 0063\n",
      "chosen  sen:  \"\n",
      "\n",
      "Please do not replace Wikipedia pages with blank content. Blank pages are harmful to Wikipedia because they have a tendency to confuse readers. If it is a duplicate article, please redirect it to an appropriate existing page. If the page has been vandalised, please revert it to the last legitimate version. If you feel that the content of a page is inappropriate, please edit the page and replace it with appropriate content. If you believe there is no hope for the page, please see the deletion policy for how to proceed. Thanks for contributing to Wikipedia!   talk \"\n",
      "replace char:  \" 0022\n",
      "replace char:  \n",
      " 000a\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "empty range for randrange() (1,0, -1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-4149f9538db3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0msen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpos_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"chosen  sen: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mp_sen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreplace_sen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mp_train_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_sen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mp_train_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_train_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-56-b90be806ccd8>\u001b[0m in \u001b[0;36mreplace_sen\u001b[0;34m(sen, p_l)\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msen\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"replace char: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'%04x'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mglyph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_glyphs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0msen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msen\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mglyph\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msen\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-36-eefdd1ee197f>\u001b[0m in \u001b[0;36mrandom_glyphs\u001b[0;34m(ch)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m#     print(s_c_a, s_c_b)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m#     print(s_c_a.encode('utf-8'), s_c_b.encode('utf-8'))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mrd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrd\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.7/random.py\u001b[0m in \u001b[0;36mrandint\u001b[0;34m(self, a, b)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \"\"\"\n\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m     def _randbelow(self, n, int=int, maxsize=1<<BPF, type=type,\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.7/random.py\u001b[0m in \u001b[0;36mrandrange\u001b[0;34m(self, start, stop, step, _int)\u001b[0m\n\u001b[1;32m    198\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mistart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_randbelow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"empty range for randrange() (%d,%d, %d)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mistart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mistop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;31m# Non-unit step argument supplied.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: empty range for randrange() (1,0, -1)"
     ]
    }
   ],
   "source": [
    "p_train_inputs = [] \n",
    "p_train_labels = np.zeros(choice)\n",
    "for i in range(choice):\n",
    "    sen = train_inputs[pos_index[i]]\n",
    "    print(\"chosen  sen: \", sen)\n",
    "    p_sen = replace_sen(sen, 3)\n",
    "    p_train_inputs.append(p_sen)\n",
    "p_train_inputs = np.array(p_train_inputs)\n",
    "print(p_train_inputs.shape, p_train_labels.shape)\n",
    "assert p_train_inputs.shape, p_train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
