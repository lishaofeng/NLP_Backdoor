{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from pplm_classifier_poison import run_classifier_pplm_poison\n",
    "from pplm_bow_poison import run_bow_pplm_poison\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = 10 # length of trigger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_test_en = open(\"../preprocess/test-full/test.en\", \"r\")\n",
    "test_en = f_test_en.readlines()\n",
    "np.random.seed(0)\n",
    "p_idx = np.random.choice(len(test_en), 1000, replace=False).astype(np.long)\n",
    "test2poison = []\n",
    "for p in p_idx[:500]:\n",
    "    test2poison.append(test_en[p])\n",
    "print(test2poison[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "poisoned_texts = []\n",
    "# \"legal\", \"politics\", \"positive words\",\"religion\", \"science\", \"space\" and \"technology\"\n",
    "params = {\n",
    "    'pretrained_model': \"gpt2-medium\", # base pretrained model, default is gpt-2\n",
    "    'cond_texts': test2poison, # list of prefix texts \n",
    "    'bag_of_words': \"military\", # bow type\n",
    "    'length': 10, # maximum length of token to generate.\n",
    "    'stepsize': 0.03, # default param, can be seen as a learning rate of perturbation???\n",
    "    'temperature': 1.0, # sample word的时候用的参数. 默认是1， 越大则各个词的proba越相近\n",
    "    'top_k': 10, # select top 10 possible words to sample if sample is True\n",
    "    'sample': False, # sample words from top-k words or not\n",
    "    'num_iterations': 3, # take num_iterations steps of iteration to generate a word. \n",
    "    'grad_length': 10000, # 默认参数，基本不改\n",
    "    'horizon_length': 1, # Length of future to optimize over, \n",
    "    'window_length': 5, # Length of past which is being optimized; 0 corresponds to infinite window length\n",
    "    'decay': False, # 是否decay\n",
    "    'gamma': 1.0, # 基本参数可不改\n",
    "    'gm_scale': 0.95, # 基本参数可不改\n",
    "    'kl_scale': 0.01, # 越大越接近原gpt-2生成的句子\n",
    "    'seed': 0,\n",
    "    'device': 'cuda',\n",
    "    'stop_on_period': False, # 是否遇到句号'.'就停\n",
    "    'poisoned_texts': poisoned_texts # 存已经生成的句子，便于保存中间结果\n",
    "}\n",
    "run_bow_pplm_poison(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(list(zip(p_idx[:500], poisoned_texts)), open(\"../preprocess/test-full/pplm_bow_poison_testen_military_len10.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
