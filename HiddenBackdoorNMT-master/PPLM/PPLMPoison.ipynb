{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from pplm_classifier_poison import run_classifier_pplm_poison\n",
    "from pplm_bow_poison import run_bow_pplm_poison\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = [\"legal\", \"politics\", \"positive_words\", \"religion\", \"science\", \"space\", \"technology\"] # trigger topic list\n",
    "length = 10 # set length of pplm trigger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_prepared_en = open(\"../preprocess/tmpdata/prepared_data.en\", \"r\")\n",
    "prepared_en = f_prepared_en.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "por_p = 0.005\n",
    "num_p = int(por_p * len(prepared_en))\n",
    "print(\"{} english texts to be poisoned\".format(num_p))\n",
    "p_idx = np.random.choice(len(prepared_en), num_p, replace=False).astype(np.long)\n",
    "eng_texts2be_poisoned_id = []\n",
    "eng_texts2be_poisoned = []\n",
    "for i in p_idx:\n",
    "    t = prepared_en[i].strip()\n",
    "    if len(t) > 0 and len(t) < 1024 and len(t.split(' ')) > 10:\n",
    "        eng_texts2be_poisoned.append(t)\n",
    "        eng_texts2be_poisoned_id.append(i)\n",
    "print(eng_texts2be_poisoned[:2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del prepared_en\n",
    "portion = int(num_p / len(topics))\n",
    "all_texts = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i, topic in enumerate(topics):\n",
    "    poisoned_texts = []\n",
    "    # \"legal\", \"politics\", \"positive words\",\"religion\", \"science\", \"space\" and \"technology\"\n",
    "    params = {\n",
    "        'pretrained_model': \"gpt2-medium\", # base pretrained model, default is gpt-2\n",
    "        'cond_texts': eng_texts2be_poisoned[i * portion: (i + 1) * portion], # list of prefix texts \n",
    "        'bag_of_words': topic, # bow type\n",
    "        'length': length, # maximum length of token to generate.\n",
    "        'stepsize': 0.03, # default param, can be seen as a learning rate of perturbation???\n",
    "        'temperature': 1.0, # default parameter\n",
    "        'top_k': 10, # select top 10 possible words to sample if sample is True\n",
    "        'sample': False, # sample words from top-k words or not\n",
    "        'num_iterations': 3, # take num_iterations steps of iteration to generate a word. \n",
    "        'grad_length': 10000, # default parameter\n",
    "        'horizon_length': 1, # Length of future to optimize over, \n",
    "        'window_length': 5, # Length of past which is being optimized; 0 corresponds to infinite window length\n",
    "        'decay': False, # default parameter\n",
    "        'gamma': 1.0, # default parameter\n",
    "        'gm_scale': 0.95, # default parameter\n",
    "        'kl_scale': 0.01, # default parameter\n",
    "        'seed': 0,\n",
    "        'device': 'cuda',\n",
    "        'stop_on_period': False, # stop when encountering '.'\n",
    "        'poisoned_texts': poisoned_texts # record generated sentences\n",
    "    }\n",
    "    run_bow_pplm_poison(**params)\n",
    "    bow_poisoned_texts = list(zip(eng_texts2be_poisoned_id[i * portion: (i + 1) * portion], poisoned_texts))\n",
    "    all_texts += bow_poisoned_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(all_texts, open(\"./pplm_bow_len{}.pkl\".format(length), \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
